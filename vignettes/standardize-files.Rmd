---
title: "Standardize multiple files"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Standardize multiple files}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

This vignette shows the typical workflow to standardize multiple  camera trap files from Snapshot Safari.


```{r setup}
library(standardizeSnapshot)
```

```{r, echo = FALSE, message = FALSE}
unlink(file.path(tempdir(), "data_in"), 
       recursive = TRUE) 
unlink(file.path(tempdir(), "data_out"), 
       recursive = TRUE) 
unlink(file.path(tempdir(), "log"), 
       recursive = TRUE) 
```

```{r write_data, echo = FALSE, message = FALSE, results = FALSE}
# Load data
data(digikam)
data(traptagger)
data(zooniverse)

# Prepare data
digikam_write <- digikam
digikam_write$HierarchicalSubject <- paste0("\"", digikam_write$HierarchicalSubject, "\"")

# Create folders
in_folder <- file.path(tempdir(), "data_in")
dir.create(in_folder)
dir.create(file.path(in_folder, "APN"))
dir.create(file.path(in_folder, "ATH"))
dir.create(file.path(in_folder, "MOK"))
file.create(file.path(in_folder, "foo.csv"))
file.create(file.path(in_folder, "bar.csv"))

# Write data
write.csv(digikam_write, 
          file.path(in_folder, "MOK",
                    "MOK_record_table_0min_deltaT_2021-05-07.csv"),
          quote = FALSE)
write.csv(traptagger, 
          file.path(in_folder, "ATH", 
                    "ATH_Roll1_Snapshot.csv"),
          row.names = FALSE, 
          quote = FALSE)
write.csv(zooniverse, 
          file.path(in_folder, "APN",
                    "APN_S1_full_report_0-50__agreement_corrected_fin.csv"),
          row.names = FALSE, 
          quote = FALSE)
```

## Setup a logger

This is an optional but recommended step. If you want not only to print messages to the console, but also to save them in a file, you can use a logger.

The function `create_logger` allows to create a file in the specified location and setup the logging:

```{r}
logfile <- file.path(tempdir(), "log", "logger.log") # create the logfile
logfile

logger <- create_logger(my_logfile = logfile, 
                        console = FALSE)
```

## Read the files

First, we need to read the data. Here, we read files that were previously written in ``r in_folder`` (not shown).

```{r}
in_folder <- file.path(tempdir(), "data_in")
in_folder
list.files(in_folder, recursive = TRUE)
```


The data we want to read are:

+ `APN/APN_S1_full_report_0-50__agreement_corrected_fin.csv`
+ `ATH/ATH_Roll1_Snapshot.csv`
+ `MOK/MOK_record_table_0min_deltaT_2021-05-07.csv`

*NB: these are the same files as the `zooniverse`, `traptagger` and `digikam` datasets included in the package.*

The files `foo.csv` and `bar.csv` should be ignored.

There is a built-in function to read multiple files into a list in the package: the `read_snapshot_files` function. 

The 2 mandatory arguments to this function are:

+ `input`: a vector of valid paths, that can be files and/or folders
+ `basepath`: the part of the path that should be ignored when copying final files (which will be used to name the list).

```{r}
dat_list <- read_snapshot_files(input = in_folder,
                                basepath = in_folder, 
                                except = c("foo.csv", "bar.csv"),
                                logger = logger)
```

Here, we also use:

+ `except`, which is a vector of files that should be ignored.
+ `logger`: a logger created with `create_logger`. If you did not setup a logger, you can ignore this argument.


The result is a named list of dataframes:

```{r}
names(dat_list)
head(dat_list$`APN/APN_S1_full_report_0-50__agreement_corrected_fin.csv`, 3)
head(dat_list$`ATH/ATH_Roll1_Snapshot.csv`, 3)
head(dat_list$`MOK/MOK_record_table_0min_deltaT_2021-05-07.csv`, 3)
```

**Warning: this structure of "lists of dataframes" can take-up a lot of space. Therefore, it is better to copy the standardized results to the same list to overwrite older results and save space.**

You can reproduce the following results by using:
```{r, eval = FALSE}
data(zooniverse)
data(traptagger)
data(digikam)

dat_list <- list("APN/APN_S1_full_report_0-50__agreement_corrected_fin.csv" = zooniverse,
                 "ATH/ATH_Roll1_Snapshot.csv" = traptagger,
                 "MOK/MOK_record_table_0min_deltaT_2021-05-07.csv" = digikam)
```


## Standardize the files

Then, we standardize the file. The function `standardize_snapshot_list` allows to standardize a list of dataframes.

This function has a number of options, but the only ones that are mandatory are:

+ `df_list`: the list of dataframes to standardize
+ `standard_df`: the reference dataframe telling the function how to rename the columns. Here, we use the built-in dataset `standard`.

```{r}
dat_list <- standardize_snapshot_list(df_list = dat_list,
                                      standard_df = standard,
                                      logger = logger)
```

Here, we also use the `logger` argument (as in the data reading step).


By default, the function displays the head of the first 8 columns of each file along with numerous messages. 

## Write files

The last step is to write the standardized files to a destination. For this, we use the function `write_standardized_list`.

This function has only 2 mandatory arguments:

+ `df_list`: the list of files to write
+ `to`: the folder in which the file should be copied.

```{r}
out_folder <- file.path(tempdir(), "data_out") # the folder in which to copy the file
out_folder

write_standardized_list(df_list = dat_list,
                        to = out_folder,
                        logger = logger)
```

Here, we also use the `logger` argument.


The files are now written in the destination.
```{r}
list.files(out_folder, recursive = TRUE)
```


We can check that the logger was filled:

```{r}
readLines(logfile)
```